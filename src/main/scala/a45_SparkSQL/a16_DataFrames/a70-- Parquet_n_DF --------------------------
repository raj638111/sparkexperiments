

   #  Reading Parquet Files into DF
      +  Schema is preserved
      
   #  Example
      // This is used to implicitly convert an RDD to a DataFrame.
      import sqlContext.implicits._
      
      val people: RDD[Person] = ... // An RDD of case class objects, from the previous example.
      
      // The RDD is implicitly converted to a DataFrame by implicits, allowing it to be stored using Parquet.
      people.write.parquet("people.parquet")
      
      // Read in the parquet file created above. Parquet files are self-describing so the schema is preserved.
      // The result of loading a Parquet file is also a DataFrame.
      val parquetFile = sqlContext.read.parquet("people.parquet")
      
      //Parquet files can also be registered as tables and then used in SQL statements.
      parquetFile.registerTempTable("parquetFile")
      val teenagers = sqlContext.sql("SELECT name FROM parquetFile WHERE age >= 13 AND age <= 19")
      teenagers.map(t => "Name: " + t(0)).collect().foreach(println)      